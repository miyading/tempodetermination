{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dafdc7e-0b52-4e60-9443-c69a24c41eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/conda/lib/python3.9/site-packages (0.41.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.9/site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.9/site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from shap) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from shap) (1.20.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.9/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from shap) (1.3.5)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/lib/python3.9/site-packages (from shap) (4.62.3)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.9/site-packages (from shap) (0.54.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>20.9->shap) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba->shap) (60.2.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba->shap) (0.37.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->shap) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->shap) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f0857b-c4e6-4895-83b0-f02e4c601ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e80538d-0e8d-437a-8037-a2df89724287",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {} \n",
    "\n",
    "def temposhap(melody_num, freq, stepsizes, contours, pre_contours, post_contours, start_tempo, iters = 5):\n",
    "    \n",
    "    df = pd.read_csv(\"Melody\"+str(melody_num)+\"_\"+str(start_tempo)+\"ms.csv\")\n",
    "\n",
    "    pd.options.mode.chained_assignment = None \n",
    "    df_fewcycles = df.head(iters*freq)\n",
    "    df_fewcycles.set_index('roundedbeat', inplace=True)\n",
    "\n",
    "    beats = list(range(freq)) * iters\n",
    "    beats = np.add(beats, 1).tolist()\n",
    "    df_fewcycles.loc[:,'beat'] = beats\n",
    "\n",
    "    stepsize = np.tile(stepsizes, iters)\n",
    "    df_fewcycles.loc[:,'stepsize'] = stepsize\n",
    "\n",
    "    contour = np.tile(contours, iters)\n",
    "    df_fewcycles.loc[:,'contour'] = contour\n",
    "\n",
    "    pre_contour = np.tile(pre_contours, iters)\n",
    "    df_fewcycles.loc[:,'pre_contour'] = pre_contour\n",
    "\n",
    "    post_contour = np.tile(post_contours, iters)\n",
    "    df_fewcycles.loc[:,'post_contour'] = post_contour\n",
    "\n",
    "    iternum = np.repeat(list(range(iters)), freq)\n",
    "    iternum = np.add(iternum, 1).tolist()\n",
    "    df_fewcycles.loc[:,'iternum'] = iternum\n",
    "    \n",
    "    categorical_features = [\"beat\"]\n",
    "    \n",
    "    passthrough_features = [\"stepsize\", \"iternum\"]\n",
    "    binary_features = [\"contour\", \"pre_contour\", \"post_contour\"]\n",
    "    target = \"meanofmeantempo\"\n",
    "\n",
    "    train_df, test_df = train_test_split(df_fewcycles, test_size=0.2, random_state=123)\n",
    "    X_train, y_train = (\n",
    "      train_df.drop(columns=[target]),\n",
    "      train_df[target],\n",
    "    )\n",
    "    X_test, y_test = (\n",
    "      test_df.drop(columns=[target]),\n",
    "      test_df[target],\n",
    "    )\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "      (\"passthrough\", passthrough_features),  \n",
    "      \n",
    "      (OneHotEncoder(drop=\"if_binary\", dtype=int, sparse=False), \n",
    "          binary_features), \n",
    "             \n",
    "      (OneHotEncoder(handle_unknown = \"ignore\", sparse= False), \n",
    "       categorical_features), \n",
    "\n",
    "    )\n",
    "\n",
    "    transformed = preprocessor.fit_transform(X_train, y_train)\n",
    "    transformed.shape\n",
    "\n",
    "\n",
    "    ohe_columns = list(\n",
    "      preprocessor.named_transformers_[\"onehotencoder-2\"].get_feature_names_out().tolist()\n",
    "    )\n",
    "    new_columns = (\n",
    "      passthrough_features + binary_features + ohe_columns\n",
    "    )\n",
    "\n",
    "    new_columns\n",
    "\n",
    "    X_train_enc = pd.DataFrame(transformed, index=X_train.index, columns=new_columns)\n",
    "    X_train_enc\n",
    "\n",
    "    pipe_rf = make_pipeline(preprocessor, RandomForestRegressor(random_state=123, n_estimators = 5, n_jobs = -1))\n",
    "    pipe_rf.fit(X_train, y_train);\n",
    "    data = {\n",
    "      \"Importance\":  np.round(pipe_rf.named_steps[\"randomforestregressor\"].feature_importances_, 3),\n",
    "    }\n",
    "    imps = pd.DataFrame(data=data, index=new_columns,).sort_values(\n",
    "      by=\"Importance\", ascending=False\n",
    "    )\n",
    "    imps\n",
    "\n",
    "    rf_explainer = shap.TreeExplainer(pipe_rf.named_steps[\"randomforestregressor\"])\n",
    "    train_rf_shap_values = rf_explainer.shap_values(X_train_enc)\n",
    "    \n",
    "    \n",
    "    data={}\n",
    "    \n",
    "    data[\"train_rf_shap_values\"]=train_rf_shap_values\n",
    "    data[\"X_train_enc\"]=X_train_enc\n",
    "    data[\"X_train\"]=X_train\n",
    "    data[\"y_train\"]=y_train\n",
    "    data[\"X_test\"]=X_test\n",
    "    data[\"y_test\"]=y_test\n",
    "    data[\"test_score\"]=pipe_rf.score(X_test, y_test)\n",
    "    results_dict[str(melody_num) + \"_\" + str(start_tempo)] = data\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d1a0675-0728-4f9d-9900-5bced949a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "melodies=[5,7,10,12,18,22,23,24,25,27,33,36,37,38,39,40,44,45,46,51,52,29]\n",
    "freqs = [16,26,24,26,17,24,23,22,20,16,21,22,29,14,20,15,16,14,17,20,21,20]\n",
    "iters = 5\n",
    "stepsizes = [\n",
    "    [2, 1, 0, 0, 4, -4, -5, -3, 5, -4, -1, -2, -2, 2, -2, 9],\n",
    "    [-5, -3, 3, -7, 4, 3, 3, -1, -4, -5, 5, 4, -4, 7, -3, -2, 3, 4, -2, -2, -1, -2, -2, 0, -1, 8],\n",
    "    [-2, -1, -2, -2, 2, 2, 1, 2, 2, -2, 2, -4, -1, -2, 3, -3, -3, 1, 2, 2, 1, -1, -2, 5],\n",
    "    [2, 2, 1, -1, 1, 2, 2, -2, -12, 2, 5, -3, 1, 5, -3, 2, 3, -7, 2, 3, -1, -2, -2, -1, 1, 0],\n",
    "    [0, 5, -1, 1, 2, 2, -4, -5, 7, -1, 1, 2, -2, 3, -3, 2, -9],\n",
    "    [2, 1, 2, 2, -4, -1, -2, 3, -1, -2, 0, 2, 1, 2, 2, -4, -1, -2, 0, 5, -2, -3, -2, 2],\n",
    "    [0, 0, 0, 0, 7, -2, 4, -2, -2, -1, -2, -2, -1, 3, 2, 1, 2, 2, -4, 4, -4, -1, -4],\n",
    "    [9, -4, 0, -1, -4, 9, -4, 0, -1, 3, 2, 1, 2, -3, -2, 7, -12, -2, 7, 3, -1, -9],\n",
    "    [0, 1, -1, -2, -2, -1, 1, 1, 1, 3, 0, 2, -2, -1, -2, -2, 2, 1, 1, 0],\n",
    "    [0, -4, 4, 1, 2, 0, 0, -3, -4, 0, 2, 2, 3, -2, -1, 0],\n",
    "    [3, -2, 11, -2, -3, -4, -2, -1, 10, -2, 7, -2, -1, 0, -2, 3, -3, -2, -1, 1, 8],\n",
    "    [-2, 0, -1, -2, -2, 2, 2, 1, 2, -2, -1, 5, 2, 1, -5, -3, -2, 2, 1, 0, -1, 3],\n",
    "    [0, 2, 2, 1, 2, 2, -2, 0, 2, -2, -2, -1, -2, 2, -4, 2, 2, 1, 2, 2, -2, 0, -2, -1, -2, -2, -1, 1, 0],\n",
    "    [5, 4, -2, 3, -1, 5, -2, -12, 2, 5, -2, -1, 1, -5],\n",
    "    [-2, -1, 5, -2, 0, -2, 0, -1, -2, -2, 0, -5, 2, 0, 2, 1, 2, -3, 1, 7],\n",
    "    [4, 3, 0, 0, 2, -2, -2, -1, -2, -2, -1, 1, 2, -2, 0],\n",
    "    [9, 3, -7, 4, -2, 3, -10, 10, -1, -4, -1, 3, -2, 4, 3, -12],\n",
    "    [-2, 7, -2, -2, -1, 3, -8, 3, -2, 4, 3, -3, -4, 4],\n",
    "    [-3, 3, -7, 4, -2, 3, -10, 10, -1, -4, -1, 1, 2, -2, 4, 3, 0],\n",
    "    [-3, -4, -1, 1, 2, -2, 2, 2, 1, -1, 3, -3, -4, 5, -1, -2, -2, -1, 1, 7],\n",
    "    [2, 1, -5, -2, -1, 1, 2, -2, -1, 5, 2, 1, 2, 2, 1, 0, 0, 0, 0, -1, -7],\n",
    "    [2, -2, 2, 2, 1, 4, -2, 2, 2, 1, -5, 2, -4, -1, 3, -2, -3, 0, -2, 0]]\n",
    "\n",
    "contours = [[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1], \n",
    "            [1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1], \n",
    "            [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
    "            [0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0],\n",
    "            [1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "            [1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
    "            [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], \n",
    "            [0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
    "            [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1],\n",
    "            [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1], \n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0], \n",
    "            [1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1], \n",
    "            [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0], \n",
    "            [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1], \n",
    "            [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1], \n",
    "            [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1], \n",
    "            [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0], \n",
    "            [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0], \n",
    "            [1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            [0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]]\n",
    "            \n",
    "pre_contours = [[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1], \n",
    "                [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], \n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1], \n",
    "                [0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0], \n",
    "                [0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], \n",
    "                [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0], \n",
    "                [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], \n",
    "                [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0], \n",
    "                [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], \n",
    "                [1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0], \n",
    "                [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0], \n",
    "                [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0], \n",
    "                [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1], \n",
    "                [0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0], \n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0], \n",
    "                [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0], \n",
    "                [1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0], \n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0], \n",
    "                [0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0], \n",
    "                [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], \n",
    "                [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]]\n",
    "post_contours = [[1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1], \n",
    "                 [1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], \n",
    "                 [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0], \n",
    "                 [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1],\n",
    "                 [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1],\n",
    "                 [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0], \n",
    "                 [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "                 [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
    "                 [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
    "                 [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
    "                 [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "                 [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], \n",
    "                 [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1], \n",
    "                 [1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1], \n",
    "                 [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1], \n",
    "                 [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1], \n",
    "                 [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0], \n",
    "                 [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0],\n",
    "                 [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0],\n",
    "                 [0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1],\n",
    "                 [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], \n",
    "                 [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1efd2-6a3d-4a19-9971-d05a8ea21ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating SHAP Plots\n",
    "# for i in range(12,22):\n",
    "#     for starting_temp in [300,375,450,525,600]:\n",
    "#         if (melodies[i]== 7 and starting_temp == 525):\n",
    "#             continue\n",
    "#         if (melodies[i]== 33 and starting_temp == 525):\n",
    "#             continue\n",
    "#         if (melodies[i]== 37 and starting_temp == 525):\n",
    "#             continue\n",
    "#         print(melodies[i], freqs[i], stepsizes[i], contours[i],pre_contours[i],post_contours[i],starting_temp)\n",
    "#         temposhap(melodies[i], freqs[i], stepsizes[i], contours[i],pre_contours[i],post_contours[i],starting_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a9d8a2e-f766-4a6f-9816-94fb02333e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing SHAP values\n",
    "results_dict = {} \n",
    "for i in range(22):\n",
    "    for starting_temp in [300,375,450,525,600]:\n",
    "        if (melodies[i]== 7 and starting_temp == 525):\n",
    "            continue\n",
    "        if (melodies[i]== 33 and starting_temp == 525):\n",
    "            continue\n",
    "        if (melodies[i]== 37 and starting_temp == 525):\n",
    "            continue\n",
    "        results_dict[str(melodies[i]) + \"_\" + str(starting_temp)] = temposhap(melodies[i], freqs[i], stepsizes[i], contours[i],pre_contours[i],post_contours[i],starting_temp)\n",
    "        \n",
    "        # Example: results_dict[\"24_525\"][\"train_rf_shap_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b0a91-c635-48db-99cd-6a9fd3429fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average SHAP values of each feature (as files) for each beat (as columns) of each starting tempo (as rows)  \n",
    "# only first two continous features used this function\n",
    "# import statistics as st\n",
    "# import csv\n",
    "# feature_names =[\"stepsize\", \"iternum\",\"contour\", \"pre_contour\", \"post_contour\",\"beat_1\"]\n",
    "# for feature in range(6): \n",
    "#     f = open('feature/feature'+ \"_\" +\n",
    "#              feature_names[feature] +\n",
    "#              '.csv', 'w')\n",
    "#     writer = csv.writer(f)\n",
    "#     tempos = [] #one csv file\n",
    "#     title = []\n",
    "#     title[0:22] = melodies[0:22]\n",
    "#     writer.writerow(title)\n",
    "#     for starting_temp in [300,375,450,525,600]:\n",
    "#         avg = [] #one row in csv file\n",
    "#         # avg.append(str(starting_temp))\n",
    "#         for i in range(22):\n",
    "#             if (melodies[i]== 7 or melodies[i]== 33 or melodies[i]== 37) and starting_temp == 525:\n",
    "#                 avg.append('')\n",
    "#                 continue\n",
    "#             avg.append(st.mean(results_dict[str(melodies[i]) + \"_\" + str(starting_temp)][\"train_rf_shap_values\"][:,feature])) \n",
    "#         writer.writerow(avg)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164f245-7994-4aba-aac0-a6491d6370e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average shap values only when corresponding binary feature is 1 for columns 3 to 6\n",
    "# import statistics as st\n",
    "# import csv\n",
    "# feature_names =[\"stepsize\", \"iternum\",\"contour\", \"pre_contour\", \"post_contour\",\"beat_1\"]\n",
    "# for feature in range(2,6):\n",
    "#     f = open('feature/feature_new'+ \"_\" +\n",
    "#              feature_names[feature] +\n",
    "#              '.csv', 'w')\n",
    "#     writer = csv.writer(f)\n",
    "#     tempos = [] #one csv file\n",
    "#     title = []\n",
    "#     title[0:22] = melodies[0:22]\n",
    "#     writer.writerow(title)\n",
    "#     for starting_temp in [300,375,450,525,600]:\n",
    "#         avg = [] #one row in csv file\n",
    "#         for i in range(22):\n",
    "#             if (melodies[i]== 7 or melodies[i]== 33 or melodies[i]== 37) and starting_temp == 525:\n",
    "#                 avg.append('')\n",
    "#                 continue\n",
    "            \n",
    "#             shap_tmp = results_dict[str(melodies[i]) + \"_\" + str(starting_temp)][\"train_rf_shap_values\"][:,feature]\n",
    "#             x_enc_tmp = results_dict[str(melodies[i]) + \"_\" + str(starting_temp)][\"X_train_enc\"][feature_names[feature]]\n",
    "          \n",
    "#             dot = np.dot(np.array(shap_tmp), np.array(x_enc_tmp))\n",
    "#             denominator = sum(np.array(x_enc_tmp))\n",
    "#             avg.append(dot/denominator) \n",
    "#         writer.writerow(avg)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4cae4d2-8dc1-49f4-bdad-1d467180d5d7",
   "metadata": {},
   "source": [
    "# R code for One Sample t-test\n",
    "setwd(\"~/Downloads\")\n",
    "\n",
    "# correct beat_1 without beat_1 = 0 \n",
    "df_new_beat_1 <- read_csv(\"TempoProject/feature_new_beat_1.csv\")\n",
    "means_new_beat_1 <- rowMeans(df_new_beat_1,na.rm = TRUE)\n",
    "df_new_beat_1_matrix <- as.matrix(df_new_beat_1)\n",
    "sds_new_beat_1 <-rowSds(df_new_beat_1_matrix,na.rm = TRUE)\n",
    "\n",
    "# correct contour \n",
    "df_new_contour <- read_csv(\"TempoProject/feature_new_contour.csv\")\n",
    "means_new_contour <- rowMeans(df_new_contour,na.rm = TRUE)\n",
    "df_new_contour_matrix <- as.matrix(df_new_contour)\n",
    "sds_new_contour <-rowSds(df_new_contour_matrix,na.rm = TRUE)\n",
    "\n",
    "# correct pre-contour \n",
    "df_new_pre_contour <- read_csv(\"TempoProject/feature_new_pre_contour.csv\")\n",
    "means_new_pre_contour <- rowMeans(df_new_pre_contour,na.rm = TRUE)\n",
    "df_new_pre_contour_matrix <- as.matrix(df_new_pre_contour)\n",
    "sds_new_pre_contour <-rowSds(df_new_pre_contour_matrix,na.rm = TRUE)\n",
    "\n",
    "# correct post-contour \n",
    "df_new_post_contour <- read_csv(\"TempoProject/feature_new_post_contour.csv\")\n",
    "means_new_post_contour <- rowMeans(df_new_post_contour,na.rm = TRUE)\n",
    "df_new_post_contour_matrix <- as.matrix(df_new_post_contour)\n",
    "sds_new_post_contour <-rowSds(df_new_post_contour_matrix,na.rm = TRUE)\n",
    "\n",
    "# stepsize \n",
    "df_stepsize <- read_csv(\"TempoProject/feature_stepsize.csv\")\n",
    "means_stepsize <- rowMeans(df_stepsize,na.rm = TRUE)\n",
    "df_stepsize_matrix <- as.matrix(df_stepsize)\n",
    "sds_stepsize <-rowSds(df_stepsize_matrix,na.rm = TRUE)\n",
    "\n",
    "# iternum \n",
    "df_iternum <- read_csv(\"TempoProject/feature_iternum.csv\")\n",
    "means_iternum <- rowMeans(df_iternum,na.rm = TRUE)\n",
    "df_iternum_matrix <- as.matrix(df_iternum)\n",
    "sds_iternum <-rowSds(df_iternum_matrix,na.rm = TRUE)\n",
    "\n",
    "t.test(df_any[i,],mean=0,sd = sds_df_any[i]) # i from 1 to 5 are 5 starting tempi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
